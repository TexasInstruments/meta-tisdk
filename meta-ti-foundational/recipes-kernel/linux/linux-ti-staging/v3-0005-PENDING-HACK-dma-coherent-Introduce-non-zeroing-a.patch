From 757d28a4b13d8b8de89583e569045d6a1b88a5e6 Mon Sep 17 00:00:00 2001
From: Beleswar Padhi <b-padhi@ti.com>
Date: Thu, 28 Aug 2025 22:14:06 +0530
Subject: [tiL6.12 PATCH v3 5/9] PENDING: HACK: dma: coherent: Introduce
 non-zeroing alloc_from_coherent()

The "__dma_alloc_from_coherent()" function always clears the allocated
buffer from the per-device coherent memory pools. There are certain use
cases when we want to allocate a memory just to mark it as used from
Kernel's POV (e.g. Early Boot where the firmware already resides in the
device's coherent memory pools). Clearing the allocated buffer in those
cases can lead to undefined behaviour and/or result in remoteproc crash.

Therefore, introduce a new function,
"__dma_alloc_from_coherent_nonzero()" which does everything same as
"__dma_alloc_from_coherent()" except it does not clear the allocated
buffer. This is complemented by introducing a non-zeroing GFP flag
"__GFP_NONZERO" which can be passed to dma_alloc_coherent() to select
the new non-zeroing allocator.

Update the rproc_alloc_carveout() function in remoteproc core to call
dma_alloc_coherent() with the __GFP_NONZERO flag to support Early Boot
and Late Attach of remote processors.

Signed-off-by: Beleswar Padhi <b-padhi@ti.com>
---
 drivers/remoteproc/remoteproc_core.c |  6 ++-
 include/linux/dma-map-ops.h          |  3 ++
 include/linux/gfp_types.h            |  3 ++
 kernel/dma/coherent.c                | 61 ++++++++++++++++++++++++++++
 kernel/dma/mapping.c                 |  9 +++-
 5 files changed, 79 insertions(+), 3 deletions(-)

diff --git a/drivers/remoteproc/remoteproc_core.c b/drivers/remoteproc/remoteproc_core.c
index f2611f0af6c2..236f8a71d197 100644
--- a/drivers/remoteproc/remoteproc_core.c
+++ b/drivers/remoteproc/remoteproc_core.c
@@ -689,10 +689,14 @@ static int rproc_alloc_carveout(struct rproc *rproc,
 	struct rproc_mem_entry *mapping = NULL;
 	struct device *dev = &rproc->dev;
 	dma_addr_t dma;
+	gfp_t gfp_flags = GFP_KERNEL;
 	void *va;
 	int ret;
 
-	va = dma_alloc_coherent(dev->parent, mem->len, &dma, GFP_KERNEL);
+	if (rproc->late_attach)
+		gfp_flags |= __GFP_NONZERO;
+
+	va = dma_alloc_coherent(dev->parent, mem->len, &dma, gfp_flags);
 	if (!va) {
 		dev_err(dev->parent,
 			"failed to allocate dma memory: len 0x%zx\n",
diff --git a/include/linux/dma-map-ops.h b/include/linux/dma-map-ops.h
index b42408a24ad1..791d40608093 100644
--- a/include/linux/dma-map-ops.h
+++ b/include/linux/dma-map-ops.h
@@ -164,6 +164,8 @@ int dma_declare_coherent_memory(struct device *dev, phys_addr_t phys_addr,
 void dma_release_coherent_memory(struct device *dev);
 int dma_alloc_from_dev_coherent(struct device *dev, ssize_t size,
 		dma_addr_t *dma_handle, void **ret);
+int dma_alloc_from_dev_coherent_nonzero(struct device *dev, ssize_t size,
+		dma_addr_t *dma_handle, void **ret);
 int dma_release_from_dev_coherent(struct device *dev, int order, void *vaddr);
 int dma_mmap_from_dev_coherent(struct device *dev, struct vm_area_struct *vma,
 		void *cpu_addr, size_t size, int *ret);
@@ -175,6 +177,7 @@ static inline int dma_declare_coherent_memory(struct device *dev,
 }
 
 #define dma_alloc_from_dev_coherent(dev, size, handle, ret) (0)
+#define dma_alloc_from_dev_coherent_nonzero(dev, size, handle, ret) (0)
 #define dma_release_from_dev_coherent(dev, order, vaddr) (0)
 #define dma_mmap_from_dev_coherent(dev, vma, vaddr, order, ret) (0)
 static inline void dma_release_coherent_memory(struct device *dev) { }
diff --git a/include/linux/gfp_types.h b/include/linux/gfp_types.h
index 65db9349f905..411dd3a4ab84 100644
--- a/include/linux/gfp_types.h
+++ b/include/linux/gfp_types.h
@@ -58,6 +58,7 @@ enum {
 #ifdef CONFIG_SLAB_OBJ_EXT
 	___GFP_NO_OBJ_EXT_BIT,
 #endif
+	___GFP_NONZERO_BIT,
 	___GFP_LAST_BIT
 };
 
@@ -103,6 +104,7 @@ enum {
 #else
 #define ___GFP_NO_OBJ_EXT       0
 #endif
+#define ___GFP_NONZERO		BIT(___GFP_NONZERO_BIT)
 
 /*
  * Physical address zone modifiers (see linux/mmzone.h - low four bits)
@@ -292,6 +294,7 @@ enum {
 #define __GFP_NOWARN	((__force gfp_t)___GFP_NOWARN)
 #define __GFP_COMP	((__force gfp_t)___GFP_COMP)
 #define __GFP_ZERO	((__force gfp_t)___GFP_ZERO)
+#define __GFP_NONZERO	((__force gfp_t)___GFP_NONZERO)
 #define __GFP_ZEROTAGS	((__force gfp_t)___GFP_ZEROTAGS)
 #define __GFP_SKIP_ZERO ((__force gfp_t)___GFP_SKIP_ZERO)
 #define __GFP_SKIP_KASAN ((__force gfp_t)___GFP_SKIP_KASAN)
diff --git a/kernel/dma/coherent.c b/kernel/dma/coherent.c
index 3b2bdca9f1d4..cc391eda7e24 100644
--- a/kernel/dma/coherent.c
+++ b/kernel/dma/coherent.c
@@ -196,6 +196,67 @@ int dma_alloc_from_dev_coherent(struct device *dev, ssize_t size,
 	return 1;
 }
 
+/* Same as __dma_alloc_from_coherent() but without memset() */
+static void *__dma_alloc_from_coherent_nonzero(struct device *dev,
+					       struct dma_coherent_mem *mem,
+					       ssize_t size, dma_addr_t *dma_handle)
+{
+	int order = get_order(size);
+	unsigned long flags;
+	int pageno;
+	void *ret;
+
+	spin_lock_irqsave(&mem->spinlock, flags);
+
+	if (unlikely(size > ((dma_addr_t)mem->size << PAGE_SHIFT)))
+		goto err;
+
+	pageno = bitmap_find_free_region(mem->bitmap, mem->size, order);
+	if (unlikely(pageno < 0))
+		goto err;
+
+	/*
+	 * Memory was found in the coherent area.
+	 */
+	*dma_handle = dma_get_device_base(dev, mem) +
+			((dma_addr_t)pageno << PAGE_SHIFT);
+	ret = mem->virt_base + ((dma_addr_t)pageno << PAGE_SHIFT);
+	spin_unlock_irqrestore(&mem->spinlock, flags);
+	return ret;
+err:
+	spin_unlock_irqrestore(&mem->spinlock, flags);
+	return NULL;
+}
+
+/**
+ * dma_alloc_from_dev_coherent_nonzero() - allocate memory from device coherent pool
+ * @dev:	device from which we allocate memory
+ * @size:	size of requested memory area
+ * @dma_handle:	This will be filled with the correct dma handle
+ * @ret:	This pointer will be filled with the virtual address
+ *		to allocated area.
+ *
+ * This function should be only called from per-arch dma_alloc_coherent()
+ * to support allocation from per-device coherent memory pools. This
+ * function is same as dma_alloc_from_dev_coherent(), except it calls
+ * the non-zeroing __dma_alloc_from_coherent_nonzero() function to
+ * prevent clearing the allocated pages.
+ *
+ * Returns 0 if dma_alloc_coherent should continue with allocating from
+ * generic memory areas, or !0 if dma_alloc_coherent should return @ret.
+ */
+int dma_alloc_from_dev_coherent_nonzero(struct device *dev, ssize_t size,
+		dma_addr_t *dma_handle, void **ret)
+{
+	struct dma_coherent_mem *mem = dev_get_coherent_memory(dev);
+
+	if (!mem)
+		return 0;
+
+	*ret = __dma_alloc_from_coherent_nonzero(dev, mem, size, dma_handle);
+	return 1;
+}
+
 static int __dma_release_from_coherent(struct dma_coherent_mem *mem,
 				       int order, void *vaddr)
 {
diff --git a/kernel/dma/mapping.c b/kernel/dma/mapping.c
index 74d453ec750a..f5152fc9804d 100644
--- a/kernel/dma/mapping.c
+++ b/kernel/dma/mapping.c
@@ -604,8 +604,13 @@ void *dma_alloc_attrs(struct device *dev, size_t size, dma_addr_t *dma_handle,
 	if (WARN_ON_ONCE(flag & __GFP_COMP))
 		return NULL;
 
-	if (dma_alloc_from_dev_coherent(dev, size, dma_handle, &cpu_addr))
-		return cpu_addr;
+	if (flag & __GFP_NONZERO) {
+		if (dma_alloc_from_dev_coherent_nonzero(dev, size, dma_handle, &cpu_addr))
+			return cpu_addr;
+	} else {
+		if (dma_alloc_from_dev_coherent(dev, size, dma_handle, &cpu_addr))
+			return cpu_addr;
+	}
 
 	/* let the implementation decide on the zone to allocate from: */
 	flag &= ~(__GFP_DMA | __GFP_DMA32 | __GFP_HIGHMEM);
-- 
2.34.1

